{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "125c8fca",
   "metadata": {},
   "source": [
    "# 04 | Scorecard & Scaling desde el modelo de Red Neuronal\n",
    "\n",
    "Este notebook parte del **Challenger NN** entrenado en `train.py` y genera un \n",
    "scorecard calibrado y escalado para uso operativo en gestión de riesgo crediticio.\n",
    "\n",
    "**Flujo general**\n",
    "1. Importar dependencias y fijar rutas.\n",
    "2. Cargar arquitectura + pesos de la red neuronal.\n",
    "3. Preparar `CreditDataset` para inferencia sobre todo el dataset.\n",
    "4. Generar probabilidades crudas `y_prob_raw`.\n",
    "5. Calibrar las probabilidades mediante *Platt Scaling* (sigmoide).\n",
    "6. Escalar probabilidades calibradas a un rango **300 – 850**.\n",
    "7. Evaluar métricas clave y guardar artefactos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72718c",
   "metadata": {},
   "source": [
    "## 1) Importar librerías y parámetros globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4390a82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, torch\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
    "\n",
    "# Carpeta donde `train.py` guardó los artefactos\n",
    "REPORT_DIR = Path(\"C:\\GitHub\\Trading\\credit-risk-ml-nn\\reports\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e64e5d9",
   "metadata": {},
   "source": [
    "## 2) Cargar arquitectura y pesos del modelo NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f546bc59",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'reports\\\\optuna_study.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cargamos estudio Optuna para conocer los mejores hiperparámetros\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m study = \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mREPORT_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moptuna_study.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m best  = study.best_trial.params\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Importamos definiciones del script de entrenamiento\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub\\Trading\\credit-risk-ml-nn\\venv\\Lib\\site-packages\\joblib\\numpy_pickle.py:735\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode, ensure_native_byte_order)\u001b[39m\n\u001b[32m    733\u001b[39m         obj = _unpickle(fobj, ensure_native_byte_order=ensure_native_byte_order)\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    736\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _validate_fileobject_and_memmap(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[32m    737\u001b[39m             fobj,\n\u001b[32m    738\u001b[39m             validated_mmap_mode,\n\u001b[32m    739\u001b[39m         ):\n\u001b[32m    740\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    741\u001b[39m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[32m    742\u001b[39m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[32m    743\u001b[39m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'reports\\\\optuna_study.pkl'"
     ]
    }
   ],
   "source": [
    "# Cargamos estudio Optuna para conocer los mejores hiperparámetros\n",
    "import joblib, importlib\n",
    "study = joblib.load(REPORT_DIR / \"optuna_study.pkl\")\n",
    "best  = study.best_trial.params\n",
    "\n",
    "# Importamos definiciones del script de entrenamiento\n",
    "train = importlib.import_module(\"train\")\n",
    "RiskNN          = train.RiskNN\n",
    "CreditDataset   = train.CreditDataset\n",
    "evaluate_probs  = train.evaluate_probs\n",
    "numerical_cols  = train.numerical_cols\n",
    "categorical_cols= train.categorical_cols\n",
    "cat_dims        = train.cat_dims\n",
    "emb_dims        = train.emb_dims\n",
    "train_ds        = train.train_ds\n",
    "DEVICE          = train.DEVICE\n",
    "\n",
    "# Reconstrucción del modelo\n",
    "nn_model = RiskNN(\n",
    "    num_features=len(numerical_cols),\n",
    "    cat_dims=cat_dims,\n",
    "    emb_dims=emb_dims,\n",
    "    hidden=best['hidden'],\n",
    "    dropout=best['dropout']\n",
    ").to(DEVICE)\n",
    "\n",
    "nn_model.load_state_dict(torch.load(REPORT_DIR / \"best_model.pth\", map_location=DEVICE))\n",
    "nn_model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ebe9d4",
   "metadata": {},
   "source": [
    "## 3) Probabilidades crudas en el dataset completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6473267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset completo\n",
    "df = pd.read_csv(\"data/processed/data_loan_complete.csv\")\n",
    "df = df[df[\"loan_status_bin\"].notna()].copy()\n",
    "df[\"target\"] = df[\"loan_status_bin\"].astype(int)\n",
    "\n",
    "# Dataset para inferencia\n",
    "full_ds = CreditDataset(\n",
    "    df, numerical_cols, categorical_cols,\n",
    "    num_stats=(train_ds.means, train_ds.stds),\n",
    "    cat_maps=train_ds.cat_maps\n",
    ")\n",
    "loader = torch.utils.data.DataLoader(full_ds, batch_size=2048, shuffle=False, num_workers=0)\n",
    "\n",
    "y_true, y_prob_raw = evaluate_probs(nn_model, loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780653f8",
   "metadata": {},
   "source": [
    "## 4) Calibración con Platt Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638a030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedNN:\n",
    "    \"\"\"Wrapper para exponer predict_proba a sklearn\"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.num_len = len(numerical_cols)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_num = torch.tensor(X[:, :self.num_len], dtype=torch.float32).to(DEVICE)\n",
    "        X_cat = torch.tensor(X[:, self.num_len:], dtype=torch.int64).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(X_num, X_cat)\n",
    "            p1 = torch.sigmoid(logits).cpu().numpy()\n",
    "        return np.vstack([1 - p1, p1]).T\n",
    "\n",
    "X_concat = np.hstack([full_ds.X_num.numpy(), full_ds.X_cat.numpy()])\n",
    "\n",
    "calibrator = CalibratedClassifierCV(base_estimator=WrappedNN(nn_model),\n",
    "                                    method='sigmoid', cv='prefit')\n",
    "calibrator.fit(X_concat, y_true)\n",
    "y_prob_cal = calibrator.predict_proba(X_concat)[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4acb799",
   "metadata": {},
   "source": [
    "## 5) Escalado a rango 300–850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d8cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_score = MinMaxScaler(feature_range=(850, 300))  # high prob -> low score\n",
    "scaler_score.fit(y_prob_cal.reshape(-1, 1))\n",
    "scores = scaler_score.transform(y_prob_cal.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Guardar objetos\n",
    "joblib.dump(calibrator, REPORT_DIR / \"nn_calibrator.pkl\")\n",
    "joblib.dump(scaler_score, REPORT_DIR / \"score_scaler_nn.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4fc8ee",
   "metadata": {},
   "source": [
    "## 6) Métricas de desempeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bbaa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- Desempeño de la red neuronal ---')\n",
    "print('ROC-AUC crudo :', roc_auc_score(y_true, y_prob_raw))\n",
    "print('ROC-AUC cal   :', roc_auc_score(y_true, y_prob_cal))\n",
    "print('PR-AUC  cal   :', average_precision_score(y_true, y_prob_cal))\n",
    "print('Brier   cal   :', brier_score_loss(y_true, y_prob_cal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a60c3db",
   "metadata": {},
   "source": [
    "## 7) Exportar scorecard a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072b7832",
   "metadata": {},
   "outputs": [],
   "source": [
    "        pd.DataFrame({\n",
    "\"\n",
    "        \"target\": y_true,\n",
    "\"\n",
    "        \"prob_raw\": y_prob_raw,\n",
    "\"\n",
    "        \"prob_cal\": y_prob_cal,\n",
    "\"\n",
    "        \"score\": scores\n",
    "\"\n",
    "        }).to_csv(REPORT_DIR / \"nn_scores.csv\", index=False)\n",
    "\"\n",
    "        print('Archivo nn_scores.csv guardado en reports/')\n",
    "\"\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
