{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da0c1a7a",
   "metadata": {},
   "source": [
    "# üìä Scoring Masivo ‚Äî Champion & Challenger\n",
    "\n",
    "Este notebook aplica scoring robusto sin errores de columnas ausentes:\n",
    "\n",
    "1. Carga de nuevas solicitudes.\n",
    "2. Carga de artefactos entrenados (Champion & Challenger).\n",
    "3. Transformaci√≥n y codificaci√≥n de datos.\n",
    "4. Scoring Champion (WOE + Regresi√≥n Log√≠stica) sin errores de dimensiones.\n",
    "5. Scoring Challenger (RiskNN) con normalizaci√≥n y calibraci√≥n.\n",
    "6. Conversi√≥n de probabilidades a score 300‚Äì900.\n",
    "7. M√©tricas opcionales si existe `target`.\n",
    "8. Exportaci√≥n de resultados.\n",
    "\n",
    "**Versi√≥n:** Junio 2025 ¬∑ *Pipeline listo para producci√≥n*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce1cf78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuraci√≥n lista ‚Äî Dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "# %% 1) IMPORTACIONES & CONFIGURACI√ìN GLOBAL\n",
    "import json, joblib, random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Directorios\n",
    "PROJ_ROOT  = Path(r\"C:/GitHub/Trading/credit-risk-ml-nn\")\n",
    "DATA_DIR   = PROJ_ROOT / \"data/new_solicitude\"\n",
    "REPORT_DIR = PROJ_ROOT / \"reports\"\n",
    "MODEL_DIR  = REPORT_DIR / \"modeloFinal\"\n",
    "\n",
    "# Semilla y dispositivo\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark     = False\n",
    "\n",
    "print(\"Configuraci√≥n lista ‚Äî Dispositivo:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d879a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 2) UTILIDADES TEMPERATURE SCALING\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class TempScaling(nn.Module):\n",
    "    \"\"\"Escala logits: logit_calibrado = logit_original / T\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.T = nn.Parameter(torch.ones(()))\n",
    "    def forward(self, logits: torch.Tensor) -> torch.Tensor:\n",
    "        return logits / self.T.clamp(min=1e-3)\n",
    "\n",
    "def optimize_temperature(logits: torch.Tensor,\n",
    "                         labels: torch.Tensor,\n",
    "                         init_temp: float = 1.0,\n",
    "                         max_iter: int = 50):\n",
    "    ts = TempScaling().to(DEVICE)\n",
    "    ts.T.data.fill_(init_temp)\n",
    "    optimizer = torch.optim.LBFGS([ts.T], lr=0.01, max_iter=max_iter)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    def closure():\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss = criterion(ts(logits), labels)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    optimizer.step(closure)\n",
    "    return ts.T.item(), ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "775e638d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevas solicitudes cargadas: (250, 14)\n"
     ]
    }
   ],
   "source": [
    "# %% 3) CARGA DE NUEVAS SOLICITUDES\n",
    "CSV_IN = DATA_DIR / \"nuevas_solicitudes.csv\"\n",
    "assert CSV_IN.exists(), f\"No existe el archivo: {CSV_IN}\"\n",
    "df_new = pd.read_csv(CSV_IN)\n",
    "print(\"Nuevas solicitudes cargadas:\", df_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0d27e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\Trading\\credit-risk-ml-nn\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artefactos cargados correctamente\n"
     ]
    }
   ],
   "source": [
    "# %% 4) CARGA DE ARTEFACTOS\n",
    "import sys\n",
    "if str(PROJ_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJ_ROOT))\n",
    "from train import RiskNN\n",
    "\n",
    "# Champion artifacts\n",
    "logreg_model = joblib.load(REPORT_DIR/\"champion\"/\"logreg_woe.pkl\")\n",
    "bins_woe     = joblib.load(REPORT_DIR/\"champion\"/\"bins_woe.pkl\")\n",
    "\n",
    "# Challenger artifacts\n",
    "meta           = json.loads((MODEL_DIR/\"model_metadata.json\").read_text())\n",
    "cat_maps       = joblib.load(MODEL_DIR/\"cat_maps.pkl\")\n",
    "scaler         = joblib.load(MODEL_DIR/\"scaler.pkl\")\n",
    "cat_cols       = meta[\"categorical_cols\"]\n",
    "numerical_cols = meta[\"numerical_cols\"]\n",
    "T_init         = meta.get(\"opt_temperature\", 1.0)\n",
    "\n",
    "model = RiskNN(\n",
    "    num_features = len(numerical_cols),\n",
    "    cat_dims     = meta[\"cat_dims\"],\n",
    "    emb_dims     = meta[\"emb_dims\"],\n",
    "    hidden       = meta[\"hidden_layers\"],\n",
    "    dropout      = meta[\"dropout\"]\n",
    ").to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_DIR/\"best_model_final.pth\", map_location=DEVICE))\n",
    "model.eval()\n",
    "print(\"Artefactos cargados correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39dac74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 5) FUNCI√ìN DE CODIFICACI√ìN ROBUSTA\n",
    "import numpy as np\n",
    "\n",
    "def encode_df(df: pd.DataFrame):\n",
    "    # Asegurar presencia de todas las columnas num√©ricas\n",
    "    df_num = df.copy()\n",
    "    for col in numerical_cols:\n",
    "        if col not in df_num.columns:\n",
    "            df_num[col] = 0.0\n",
    "    # Variables num√©ricas normalizadas\n",
    "    X_num = scaler.transform(df_num[numerical_cols].fillna(0))\n",
    "    # Variables categ√≥ricas con '__unk__'\n",
    "    X_cat = np.stack([\n",
    "        df[col].map(lambda v: cat_maps[col].get(v, cat_maps[col].get(\"__unk__\", 0))).values\n",
    "        for col in cat_cols\n",
    "    ], axis=1).astype(\"int64\")\n",
    "    return X_num.astype(\"float32\"), X_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cff7e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\Trading\\credit-risk-ml-nn\\venv\\Lib\\site-packages\\scorecardpy\\germancredit.py:5: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] converting into woe values ...\n",
      "Scoring Champion completado sin errores\n"
     ]
    }
   ],
   "source": [
    "# %% 6) SCORING CHAMPION robusto (WOE + RegLog)\n",
    "import scorecardpy as sc\n",
    "\n",
    "df_woe = sc.woebin_ply(df_new.copy(), bins_woe)\n",
    "exp_cols = list(logreg_model.feature_names_in_)\n",
    "X_woe = pd.DataFrame(0.0, index=df_woe.index, columns=exp_cols)\n",
    "for c in exp_cols:\n",
    "    if c in df_woe.columns:\n",
    "        X_woe[c] = df_woe[c]\n",
    "X_woe = X_woe.fillna(0.0)\n",
    "\n",
    "p_bad = logreg_model.predict_proba(X_woe)[:, 1]\n",
    "df_new[\"P_default_CH\"] = p_bad\n",
    "df_new[\"P_pay_CH\"]     = 1 - p_bad\n",
    "\n",
    "print(\"Scoring Champion completado sin errores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c17a0460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\Trading\\credit-risk-ml-nn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Challenger completado\n"
     ]
    }
   ],
   "source": [
    "# %% 7) SCORING CHALLENGER (RiskNN) con calibraci√≥n\n",
    "num, cat = encode_df(df_new)\n",
    "with torch.no_grad():\n",
    "    logits = model(torch.from_numpy(num).to(DEVICE),\n",
    "                   torch.from_numpy(cat).to(DEVICE)) / T_init\n",
    "    p_bad_nn = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "df_new[\"P_default_NN\"] = p_bad_nn\n",
    "df_new[\"P_pay_NN\"]     = 1 - p_bad_nn\n",
    "\n",
    "print(\"Scoring Challenger completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b057f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Conversi√≥n a score completada\n"
     ]
    }
   ],
   "source": [
    "# %% 8) CONVERTIR PROBABILIDADES A SCORE [300‚Äì900]\n",
    "BASE_SCORE, PDO, BASE_ODDS = 600, 20, 50\n",
    "factor = PDO / np.log(2)\n",
    "offset = BASE_SCORE - factor * np.log(BASE_ODDS)\n",
    "\n",
    "def pd_to_score(pd):\n",
    "    odds = (1 - pd) / pd\n",
    "    return np.clip(np.round(offset + factor * np.log(odds)), 300, 900)\n",
    "\n",
    "df_new[\"score_CH\"] = pd_to_score(df_new[\"P_default_CH\"])\n",
    "df_new[\"score_NN\"] = pd_to_score(df_new[\"P_default_NN\"])\n",
    "print(\" Conversi√≥n a score completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03e616dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC Champion: 0.7918 | ROC Challenger: 0.4299\n"
     ]
    }
   ],
   "source": [
    "# %% 9) M√âTRICAS OPCIONALES (si existe 'target')\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "if \"target\" in df_new.columns:\n",
    "    y_true = df_new[\"target\"].astype(int)\n",
    "    roc_ch = skm.roc_auc_score(y_true, df_new[\"P_default_CH\"])\n",
    "    roc_nn = skm.roc_auc_score(y_true, df_new[\"P_default_NN\"])\n",
    "    metrics = {\"ROC_CH\": float(roc_ch), \"ROC_NN\": float(roc_nn)}\n",
    "    with open(REPORT_DIR/\"test_metrics.json\", \"w\") as fp:\n",
    "        json.dump(metrics, fp, indent=2)\n",
    "    print(f\" ROC Champion: {roc_ch:.4f} | ROC Challenger: {roc_nn:.4f}\")\n",
    "else:\n",
    "    print(\" Columna 'target' no detectada; m√©tricas omitidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87281abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportado a: C:\\GitHub\\Trading\\credit-risk-ml-nn\\reports\\predictions\\predicciones_20250614_040631.csv\n"
     ]
    }
   ],
   "source": [
    "# %% 10) EXPORTAR RESULTADOS\n",
    "out = REPORT_DIR/\"predictions\"/f\"predicciones_{pd.Timestamp.now():%Y%m%d_%H%M%S}.csv\"\n",
    "out.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_new.to_csv(out, index=False)\n",
    "print(\"Exportado a:\", out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
