{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "125c8fca",
   "metadata": {},
   "source": [
    "# 04 | Scorecard & Scaling desde el modelo de Red Neuronal\n",
    "\n",
    "Este notebook parte del **Challenger NN** entrenado en `train.py` y genera un \n",
    "scorecard calibrado y escalado para uso operativo en gestión de riesgo crediticio.\n",
    "\n",
    "**Flujo general**\n",
    "1. Importar dependencias y fijar rutas.\n",
    "2. Cargar arquitectura + pesos de la red neuronal.\n",
    "3. Preparar `CreditDataset` para inferencia sobre todo el dataset.\n",
    "4. Generar probabilidades crudas `y_prob_raw`.\n",
    "5. Calibrar las probabilidades mediante *Platt Scaling* (sigmoide).\n",
    "6. Escalar probabilidades calibradas a un rango **300 – 850**.\n",
    "7. Evaluar métricas clave y guardar artefactos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72718c",
   "metadata": {},
   "source": [
    "## 1) Importar librerías y parámetros globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4390a82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, torch\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
    "\n",
    "# Carpeta donde `train.py` guardó los artefactos\n",
    "REPORT_DIR = Path(\"C:/GitHub/trading/credit-risk-ml-nn/reports\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e64e5d9",
   "metadata": {},
   "source": [
    "## 2) Cargar arquitectura y pesos del modelo NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f777cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Módulos buscados en: C:\\GitHub\\Trading\\credit-risk-ml-nn\n"
     ]
    }
   ],
   "source": [
    "# %% 0 | Ajustar sys.path para poder importar train.py\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) Pon aquí la carpeta donde está train.py:\n",
    "REPO_ROOT = Path(\"C:/Github/trading/credit-risk-ml-nn\").resolve()\n",
    "\n",
    "# 2) Inserta REPO_ROOT en sys.path si no está ya\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "# 3) Comprobación\n",
    "print(\"Módulos buscados en:\", sys.path[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f546bc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python buscará módulos en: C:\\GitHub\\Trading\\credit-risk-ml-nn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\Trading\\credit-risk-ml-nn\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# %% 1 | Ajustar sys.path para importar train.py\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Comprueba\n",
    "print(\"Python buscará módulos en:\", sys.path[0])\n",
    "\n",
    "# %% 2 | Importar definiciones del script de entrenamiento\n",
    "import train\n",
    "RiskNN        = train.RiskNN\n",
    "CreditDataset = train.CreditDataset\n",
    "train_one_epoch   = train.train_one_epoch\n",
    "evaluate_probs    = train.evaluate_probs\n",
    "evaluate_metrics  = train.evaluate_metrics\n",
    "# …importa todas las funciones/clases que necesites\n",
    "\n",
    "# %% 3 | Ahora puedes usar tu modelo y loaders\n",
    "# Por ejemplo:\n",
    "# model = RiskNN(len(numerical_cols), cat_dims, emb_dims, hidden=(256,128), dropout=0.3).to(device)\n",
    "# model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "# model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ebe9d4",
   "metadata": {},
   "source": [
    "## 3) Probabilidades crudas en el dataset completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6473267f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️  Pesos cargados desde reports\\modeloFinal\\best_model_final.pth\n",
      "{\n",
      "  \"roc\": 0.672795445623447,\n",
      "  \"pr\": 0.35794946071878425,\n",
      "  \"brier\": 0.22303508210400796,\n",
      "  \"accuracy\": 0.6295050832309239,\n",
      "  \"precision\": 0.31979866366552645,\n",
      "  \"recall\": 0.6135432428296979,\n",
      "  \"f1\": 0.4204468004543733,\n",
      "  \"f2\": 0.5183240358265205\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# %% 0 | Rutas y device -------------------------------------------------\n",
    "from pathlib import Path\n",
    "import sys, joblib, torch, pandas as pd, numpy as np, json\n",
    "\n",
    "REPO_ROOT = Path(r\"C:/Github/trading/credit-risk-ml-nn\").resolve()\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH  = 2048   # mismo batch del entrenamiento\n",
    "\n",
    "# %% 1 | Importa utilidades de train.py ---------------------------------\n",
    "import train                          # train.py debe estar en REPO_ROOT\n",
    "RiskNN            = train.RiskNN\n",
    "CreditDataset     = train.CreditDataset\n",
    "evaluate_probs    = train.evaluate_probs\n",
    "evaluate_metrics  = train.evaluate_metrics\n",
    "\n",
    "# %% 2 | Carga CSV y recrea splits idénticos ----------------------------\n",
    "DATA_PATH = REPO_ROOT / \"data\" / \"processed\" / \"data_loan_complete.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df[df[\"loan_status_bin\"].notna()].copy()\n",
    "df[\"target\"] = df[\"loan_status_bin\"].astype(int)\n",
    "df.drop(columns=[\"loan_status_bin\"], inplace=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "SEED = 42\n",
    "train_df, test_df  = train_test_split(\n",
    "    df, test_size=0.15, stratify=df[\"target\"], random_state=SEED\n",
    ")\n",
    "train_df, valid_df = train_test_split(\n",
    "    train_df, test_size=0.1765, stratify=train_df[\"target\"], random_state=SEED\n",
    ")\n",
    "\n",
    "categorical_cols = [c for c in df.columns if df[c].dtype == \"object\"]\n",
    "numerical_cols   = [c for c in df.columns if c not in categorical_cols + [\"target\"]]\n",
    "\n",
    "# %% 3 | Estadísticos y mapeos del train --------------------------------\n",
    "train_ds = CreditDataset(train_df, numerical_cols, categorical_cols)\n",
    "\n",
    "# %% 4 | Localiza y carga el estudio de Optuna --------------------------\n",
    "study_candidates = [\n",
    "    REPO_ROOT / \"reports\" / \"modeloFinal\" / \"optuna_study.pkl\",\n",
    "    REPO_ROOT / \"reports\" / \"optuna_study.pkl\",\n",
    "]\n",
    "for p in study_candidates:\n",
    "    if p.exists():\n",
    "        study_path = p\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(\"❌ No encontré optuna_study.pkl en reports/ ni reports/modeloFinal/\")\n",
    "\n",
    "best = joblib.load(study_path).best_trial.params\n",
    "hidden  = tuple(best[\"hidden\"])      # e.g. (256,128,64)\n",
    "dropout = best[\"dropout\"]\n",
    "\n",
    "# Embeddings en el mismo orden del entrenamiento\n",
    "cat_dims = [train_df[c].nunique() for c in categorical_cols]\n",
    "emb_dims = [min(50, d//2 + 1) for d in cat_dims]\n",
    "\n",
    "# %% 5 | Localiza pesos del modelo y lo reconstruye ---------------------\n",
    "weight_candidates = [\n",
    "    REPO_ROOT / \"reports\" / \"modeloFinal\" / \"best_model_final.pth\",\n",
    "    REPO_ROOT / \"reports\" / \"modeloFinal\" / \"best_model.pth\",\n",
    "    REPO_ROOT / \"reports\" / \"best_model.pth\",\n",
    "]\n",
    "for p in weight_candidates:\n",
    "    if p.exists():\n",
    "        model_path = p\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(\"❌ No encontré best_model*.pth en reports/ ni reports/modeloFinal/\")\n",
    "\n",
    "nn_model = RiskNN(\n",
    "    num_features=len(numerical_cols),\n",
    "    cat_dims    =cat_dims,\n",
    "    emb_dims    =emb_dims,\n",
    "    hidden      =hidden,\n",
    "    dropout     =dropout\n",
    ").to(DEVICE)\n",
    "\n",
    "nn_model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "nn_model.eval()\n",
    "print(f\"✔️  Pesos cargados desde {model_path.relative_to(REPO_ROOT)}\")\n",
    "\n",
    "# %% 6 | Inferencia y métricas sobre TODO el dataframe ------------------\n",
    "full_ds = CreditDataset(\n",
    "    df, numerical_cols, categorical_cols,\n",
    "    num_stats=(train_ds.means, train_ds.stds),\n",
    "    cat_maps=train_ds.cat_maps\n",
    ")\n",
    "loader = torch.utils.data.DataLoader(full_ds, batch_size=BATCH, shuffle=False)\n",
    "\n",
    "y_true, y_prob = evaluate_probs(nn_model, loader)\n",
    "print(json.dumps(evaluate_metrics(y_true, y_prob), indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780653f8",
   "metadata": {},
   "source": [
    "## 4) Calibración con Platt Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638a030c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1285965194.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mMétricas calibradas:\u001b[39m\n             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Pesos de la red cargados\n",
    "...\n",
    "Métricas calibradas:\n",
    "{\n",
    "  \"roc\": 0.6731,\n",
    "  \"pr\": 0.3580,\n",
    "  ...\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0bc982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4acb799",
   "metadata": {},
   "source": [
    "## 5) Escalado a rango 300–850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d8cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_score = MinMaxScaler(feature_range=(850, 300))  # high prob -> low score\n",
    "scaler_score.fit(y_prob_cal.reshape(-1, 1))\n",
    "scores = scaler_score.transform(y_prob_cal.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Guardar objetos\n",
    "joblib.dump(calibrator, REPORT_DIR / \"nn_calibrator.pkl\")\n",
    "joblib.dump(scaler_score, REPORT_DIR / \"score_scaler_nn.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4fc8ee",
   "metadata": {},
   "source": [
    "## 6) Métricas de desempeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bbaa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- Desempeño de la red neuronal ---')\n",
    "print('ROC-AUC crudo :', roc_auc_score(y_true, y_prob_raw))\n",
    "print('ROC-AUC cal   :', roc_auc_score(y_true, y_prob_cal))\n",
    "print('PR-AUC  cal   :', average_precision_score(y_true, y_prob_cal))\n",
    "print('Brier   cal   :', brier_score_loss(y_true, y_prob_cal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a60c3db",
   "metadata": {},
   "source": [
    "## 7) Exportar scorecard a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072b7832",
   "metadata": {},
   "outputs": [],
   "source": [
    "        pd.DataFrame({\n",
    "\"\n",
    "        \"target\": y_true,\n",
    "\"\n",
    "        \"prob_raw\": y_prob_raw,\n",
    "\"\n",
    "        \"prob_cal\": y_prob_cal,\n",
    "\"\n",
    "        \"score\": scores\n",
    "\"\n",
    "        }).to_csv(REPORT_DIR / \"nn_scores.csv\", index=False)\n",
    "\"\n",
    "        print('Archivo nn_scores.csv guardado en reports/')\n",
    "\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
